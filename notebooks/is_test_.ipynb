{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm\n",
    "import netket as nk\n",
    "import optax\n",
    "import netket.jax as nkjax\n",
    "# import netket_pro as nkp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from grad_sample.tasks.fullsum_train import Trainer\n",
    "from grad_sample.utils.is_distrib import *\n",
    "from grad_sample.utils.plotting_setup import *\n",
    "from grad_sample.is_hpsi.expect import *\n",
    "from grad_sample.is_hpsi.qgt import QGTJacobianDenseImportanceSampling\n",
    "from grad_sample.is_hpsi.operator import IS_Operator\n",
    "from netket.jax._jacobian.logic import _multiply_by_pdf\n",
    "from grad_sample.utils.tree_op import dagger_pytree, vjp_pytree, mul_pytree, shape_tree, pytree_mean\n",
    "from grad_sample.tasks.fullsum_snr_is import _compute_S_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': '5', 'is_mode': None, 'solver_fn': {'_target_': 'netket.optimizer.solver.cholesky'}, 'lr': 0.0022, 'diag_shift': 'schedule', 'n_iter': 6000, 'sample_size': 9, 'chunk_size_jac': 1024, 'chunk_size_vmap': 100, 'save_every': 10, 'run_index': 0, 'base_path': '/scratch/.amisery/grad_sample_fullsum/', 'model': {'_target_': 'grad_sample.models.heisenberg.XXZ', 'h': 1.5, 'L': 16}, 'ansatz': {'_target_': 'netket.models.RBM', 'alpha': 3, 'param_dtype': 'complex'}, 'task': {'_target_': 'grad_sample.tasks.fullsum_snr_is.FullSumIS'}}\n",
      "{'_target_': 'grad_sample.tasks.fullsum_snr_is.FullSumIS'}\n",
      "[CudaDevice(id=0)]\n",
      "{'_target_': 'netket.models.RBM', 'alpha': 3, 'param_dtype': 'complex'}\n",
      "MC state loaded, num samples 512\n",
      "/scratch/.amisery/grad_sample_fullsum//xxz_1.5/L16/RBM/alpha3/MC_9/0.0022_schedule/run_0\n",
      "The ground state energy is: -33.711056040864676\n"
     ]
    }
   ],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"base\")\n",
    "    OmegaConf.set_struct(cfg, True)\n",
    "    print(cfg)\n",
    "    print(cfg.task)\n",
    "    # cfg = OmegaConf.to_yaml(cfg)\n",
    "    # take any task from cfg and run it\n",
    "# analysis = FullSumPruning(cfg)\n",
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "num_resample = 1000\n",
    "chunk_size_resample = 100\n",
    "Nsample = 2**trainer.sample_size\n",
    "is_op = IS_Operator(operator = trainer.model.H_jax, is_mode=alpha)\n",
    "log_q, log_q_vars = is_op.get_log_importance(trainer.vstate)\n",
    "\n",
    "compute_S_F = jax.jit(nkjax.vmap_chunked(lambda s : _compute_S_F(s, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_q, log_q_vars, trainer.chunk_size_jac, is_op, trainer.solver_fn, 1e-3), in_axes=0, chunk_size = chunk_size_resample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# with jax.checking_leaks():\n",
    "# samples = trainer.vstate.sample_distribution(\n",
    "# log_q,\n",
    "# variables=log_q_vars, n_samples = Nsample\n",
    "# )\n",
    "# samples = trainer.vstate.samples\n",
    "\n",
    "# test compared to netket when alpha is 2\n",
    "# O_exp, O_grad, ng  = _compute_S_F(samples, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_q, log_q_vars, trainer.chunk_size_jac//2, is_op, trainer.solver_fn, trainer.diag_shift(0))\n",
    "# exp_netket, grad_netket = trainer.vstate.expect_and_grad(trainer.model.H_jax)\n",
    "# jax.tree_util.tree_map(lambda x,y: x/y, O_grad, grad_netket)\n",
    "\n",
    "# batch_sample = samples.reshape((num_resample, 1, Nsample, -1))\n",
    "# e, grad_e , ng = compute_S_F(batch_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "samples = trainer.vstate.sample_distribution(\n",
    "log_q,\n",
    "variables=log_q_vars, n_samples = Nsample\n",
    ")\n",
    "O_exp, O_grad, ng  = _compute_S_F(samples, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_q, log_q_vars, trainer.chunk_size_jac//2, is_op, trainer.solver_fn, trainer.diag_shift(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# estimate gradient variance with resampling\n",
    "samples = trainer.vstate.sample_distribution(\n",
    "log_q,\n",
    "variables=log_q_vars, n_samples = Nsample * num_resample\n",
    ")\n",
    "batch_sample = samples.reshape((num_resample, 1, Nsample, -1))\n",
    "e, grad_e , ng = compute_S_F(batch_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "var_resampling = tree_map(lambda g : jnp.var(g, axis=0), grad_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test compared to theoretical variance formula\n",
    "def expect_grad_var(\n",
    "    force, log_psi, parameters, model_state, log_q, q_vars, operator, sigma_psi_sq, sigma_alpha, chunk_size\n",
    "):\n",
    "    O = operator.operator\n",
    "    parameters = {\"params\": parameters}\n",
    "\n",
    "    sigma_psi_sq = sigma_psi_sq.reshape(sigma_psi_sq.shape[0]*sigma_psi_sq.shape[1], -1)\n",
    "    sigma_alpha = sigma_alpha.reshape(sigma_alpha.shape[0]*sigma_alpha.shape[1], -1)\n",
    "\n",
    "    n_samples = sigma_psi_sq.shape[0]\n",
    "\n",
    "    # Compute standard Expectation value\n",
    "    log_psi_sigma_psi_sq = nkjax.apply_chunked(lambda x: log_psi(parameters, x), chunk_size=chunk_size)(sigma_psi_sq)\n",
    "    log_q_sigma_psi_sq = nkjax.apply_chunked(lambda x: log_q(q_vars, x), chunk_size=chunk_size)(sigma_psi_sq)\n",
    "\n",
    "    log_psi_sigma_alpha = nkjax.apply_chunked(lambda x: log_psi(parameters, x), chunk_size=chunk_size)(sigma_alpha)\n",
    "    log_q_sigma_alpha = nkjax.apply_chunked(lambda x: log_q(q_vars, x), chunk_size=chunk_size)(sigma_alpha)\n",
    "\n",
    "    # estimate local forces for new sample\n",
    "    eta, etap_mels = O.get_conn_padded(sigma_psi_sq)\n",
    "    _eta = eta.reshape(-1, eta.shape[-1])\n",
    "    log_psi_eta = nkjax.apply_chunked(lambda x: log_psi(parameters, x), chunk_size=chunk_size)(\n",
    "        _eta\n",
    "    )\n",
    "\n",
    "    # del _eta_Hpsi\n",
    "    log_psi_eta = log_psi_eta.reshape(eta.shape[:-1])\n",
    "    w_is_sigma_psi_sq = jnp.abs(jnp.exp(log_psi_sigma_psi_sq - log_q_sigma_psi_sq))**2\n",
    "\n",
    "    w_is_sigma_alpha = jnp.abs(jnp.exp(log_psi_sigma_alpha - log_q_sigma_alpha))**2\n",
    "    Z_ratio = 1/nkstats.mean(w_is_sigma_alpha)\n",
    "\n",
    "    op_loc = jnp.sum(etap_mels * jnp.exp(log_psi_eta- jnp.expand_dims(log_psi_sigma_psi_sq, axis=-1)), axis=-1)\n",
    "    O_mean = nkstats.mean(op_loc)\n",
    "    op_loc_c = op_loc - O_mean\n",
    "\n",
    "    jac_mode  = operator.mode\n",
    "    # compute centered jacobian with psi squared samples\n",
    "    jacobian_pytree_c = nkjax.jacobian(\n",
    "        lambda w, sigma: log_psi(w, sigma),\n",
    "        parameters[\"params\"],\n",
    "        sigma_psi_sq,\n",
    "        model_state,\n",
    "        mode = jac_mode,\n",
    "        chunk_size=chunk_size,\n",
    "        dense=False,\n",
    "        center=True\n",
    "    )\n",
    "    force_pytree_unrolled = mul_pytree(dagger_pytree(jacobian_pytree_c), op_loc_c)\n",
    "    loc_var = tree_map(lambda x,y: jnp.mean(jnp.broadcast_to(w_is_sigma_psi_sq * Z_ratio, y.shape) * jnp.abs(jnp.expand_dims(x.T,-1)-y)**2, axis=-1), force, force_pytree_unrolled)\n",
    "    \n",
    "    log_modulus_sigma = nkjax.apply_chunked(lambda x: jnp.log(jnp.abs(jnp.exp(log_psi(parameters, x)))), chunk_size=chunk_size)(sigma_psi_sq)\n",
    "    log_modulus_sigma -= jnp.mean(log_modulus_sigma)\n",
    "    grad_var = tree_map(lambda x,y: -jnp.mean(jnp.broadcast_to(w_is_sigma_psi_sq * Z_ratio * log_modulus_sigma, y.shape) * jnp.abs(jnp.expand_dims(x.T,-1)-y)**2, axis=-1), force, force_pytree_unrolled)\n",
    "\n",
    "    return loc_var, grad_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "samples_alpha = trainer.vstate.sample_distribution(\n",
    "log_q,\n",
    "variables=log_q_vars, n_samples = Nsample\n",
    ")\n",
    "var_exact, grad_var = expect_grad_var(O_grad, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_q, log_q_vars, is_op, trainer.vstate.samples, samples_alpha, trainer.chunk_size_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # try optimizing alpha starting at alpha =2\n",
    "# lr=2400\n",
    "# alpha_s = 2.0\n",
    "# n_steps = 20\n",
    "# al = []\n",
    "# varl = []\n",
    "# gradvarl = []\n",
    "# for n in tqdm(range(n_steps)):\n",
    "#     is_ops = IS_Operator(operator = trainer.model.H_jax, is_mode=alpha_s)\n",
    "#     log_qs, log_qs_vars = is_ops.get_log_importance(trainer.vstate)\n",
    "#     samples_alphas = trainer.vstate.sample_distribution(\n",
    "#                                             log_qs,\n",
    "#                                             variables=log_qs_vars, n_samples = Nsample\n",
    "#                                             )\n",
    "\n",
    "#     O_exp, O_grad, ng  = _compute_S_F(samples_alphas, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_q, log_q_vars, trainer.chunk_size_jac//2, is_op, trainer.solver_fn, trainer.diag_shift(0))\n",
    "\n",
    "#     var_exact, grad_var = expect_grad_var(O_grad, trainer.vstate._apply_fun, trainer.vstate.parameters, trainer.vstate.model_state, log_qs, log_qs_vars, is_ops, trainer.vstate.samples, samples_alphas, trainer.chunk_size_jac)\n",
    "#     varl.append(pytree_mean(var_exact))\n",
    "#     gradvarl.append(pytree_mean(grad_var))\n",
    "#     al.append(alpha_s)\n",
    "#     alpha_s -= lr*pytree_mean(grad_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer_fun, optimizer_state, dp, params):\n",
    "    updates, new_optimizer_state = optimizer_fun(dp, optimizer_state, params)\n",
    "\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    return new_optimizer_state, new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function optax.schedules._inject.inject_hyperparams.<locals>.wrapped_transform.<locals>.update_fn(updates, state, params=None, **extra_args)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.opt.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 732/1000 [03:41<00:56,  4.71it/s, E = -33.70668437197831 ; alpha = 0.74] "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize variables\n",
    "alpha_s = 2.0\n",
    "n_iter = 1000\n",
    "epsilon = 1e-8  # Small constant to prevent division by zero\n",
    "grad_accum = 0.0  # Accumulated squared gradients\n",
    "al = []\n",
    "varl = []\n",
    "gradvarl = []\n",
    "is_ops = IS_Operator(operator=trainer.model.H_jax, is_mode=alpha_s)\n",
    "opt_state = trainer.opt.init(trainer.vstate.parameters)\n",
    "with tqdm(\n",
    "                total=n_iter,\n",
    "                disable=False,\n",
    "                dynamic_ncols=True,\n",
    "            ) as pbar:\n",
    "    # Optimization loop\n",
    "    for n in tqdm(range(n_iter)):\n",
    "        # Create IS operator and get log importance weights\n",
    "        log_qs, log_qs_vars = is_ops.get_log_importance(trainer.vstate)\n",
    "        \n",
    "        # Sample from the distribution\n",
    "        samples_alphas = trainer.vstate.sample_distribution(\n",
    "            log_qs,\n",
    "            variables=log_qs_vars,\n",
    "            n_samples=trainer.Nsample\n",
    "        )\n",
    "        \n",
    "        # Compute the observable and its gradients\n",
    "        O_exp, O_grad, ng = _compute_S_F(\n",
    "            samples_alphas,\n",
    "            trainer.vstate._apply_fun,\n",
    "            trainer.vstate.parameters,\n",
    "            trainer.vstate.model_state,\n",
    "            log_qs,\n",
    "            log_qs_vars,\n",
    "            trainer.chunk_size_jac // 2,\n",
    "            is_ops,\n",
    "            trainer.solver_fn,\n",
    "            1e-4\n",
    "        )\n",
    "        opt_state, trainer.vstate.parameters = apply_gradient(trainer.opt.update, opt_state, ng[0], trainer.vstate.parameters)\n",
    "        pbar.set_postfix_str(\n",
    "                            \"E = %s ; alpha = %.2f\"%(O_exp, alpha_s)\n",
    "                    )\n",
    "        pbar.update(1)\n",
    "        if n%10 == 1:\n",
    "            # Compute variance and gradient variance\n",
    "            var_exact, grad_var = expect_grad_var(\n",
    "                O_grad,\n",
    "                trainer.vstate._apply_fun,\n",
    "                trainer.vstate.parameters,\n",
    "                trainer.vstate.model_state,\n",
    "                log_qs,\n",
    "                log_qs_vars,\n",
    "                is_ops,\n",
    "                trainer.vstate.samples,\n",
    "                samples_alphas,\n",
    "                trainer.chunk_size_jac\n",
    "            )\n",
    "            \n",
    "            # Compute mean of variance and gradient variance\n",
    "            varl.append(pytree_mean(var_exact))\n",
    "            grad_var_mean = pytree_mean(grad_var)\n",
    "            gradvarl.append(grad_var_mean)\n",
    "            al.append(alpha_s)\n",
    "            \n",
    "            # Adagrad update\n",
    "            grad_accum += grad_var_mean**2  # Accumulate squared gradient\n",
    "            step_size = 1.0 / (np.sqrt(grad_accum) + epsilon)  # Compute adaptive step size\n",
    "            alpha_s -= step_size * grad_var_mean  # Update alpha_s\n",
    "            is_ops._is_mode = alpha_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m      2\u001b[0m axes\u001b[38;5;241m.\u001b[39mplot(al)\n\u001b[1;32m      3\u001b[0m axes1 \u001b[38;5;241m=\u001b[39m axes\u001b[38;5;241m.\u001b[39mtwinx()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(al)\n",
    "axes1 = axes.twinx()\n",
    "axes1.plot(varl, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize variables\n",
    "alpha_s = jnp.array(2.0)  # alpha_s as a JAX array for compatibility\n",
    "n_steps = 20\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optax.adagrad(learning_rate=1.0, eps=1e-8)  # Adagrad optimizer\n",
    "opt_state = optimizer.init(alpha_s)  # Initialize optimizer state\n",
    "\n",
    "al = []\n",
    "varl = []\n",
    "gradvarl = []\n",
    "\n",
    "# Optimization loop\n",
    "for n in tqdm(range(n_steps)):\n",
    "    # Create IS operator and get log importance weights\n",
    "    is_ops = IS_Operator(operator=trainer.model.H_jax, is_mode=alpha_s)\n",
    "    log_qs, log_qs_vars = is_ops.get_log_importance(trainer.vstate)\n",
    "    \n",
    "    # Sample from the distribution\n",
    "    samples_alphas = trainer.vstate.sample_distribution(\n",
    "        log_qs,\n",
    "        variables=log_qs_vars,\n",
    "        n_samples=Nsample\n",
    "    )\n",
    "    \n",
    "    # Compute the observable and its gradients\n",
    "    O_exp, O_grad, ng = _compute_S_F(\n",
    "        samples_alphas,\n",
    "        trainer.vstate._apply_fun,\n",
    "        trainer.vstate.parameters,\n",
    "        trainer.vstate.model_state,\n",
    "        log_qs,\n",
    "        log_qs_vars,\n",
    "        trainer.chunk_size_jac // 2,\n",
    "        is_ops,\n",
    "        trainer.solver_fn,\n",
    "        trainer.diag_shift(0)\n",
    "    )\n",
    "    \n",
    "    # Compute variance and gradient variance\n",
    "    var_exact, grad_var = expect_grad_var(\n",
    "        O_grad,\n",
    "        trainer.vstate._apply_fun,\n",
    "        trainer.vstate.parameters,\n",
    "        trainer.vstate.model_state,\n",
    "        log_qs,\n",
    "        log_qs_vars,\n",
    "        is_ops,\n",
    "        trainer.vstate.samples,\n",
    "        samples_alphas,\n",
    "        trainer.chunk_size_jac\n",
    "    )\n",
    "    \n",
    "    # Compute mean of variance and gradient variance\n",
    "    varl.append(pytree_mean(var_exact))\n",
    "    grad_var_mean = pytree_mean(grad_var)\n",
    "    gradvarl.append(grad_var_mean)\n",
    "    al.append(alpha_s)\n",
    "    \n",
    "    # Compute the gradient update using Optax\n",
    "    updates, opt_state = optimizer.update(grad_var_mean, opt_state)\n",
    "    alpha_s = optax.apply_updates(alpha_s, updates)  # Update alpha_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "is_ops = IS_Operator(operator = trainer.model.H_jax, is_mode=alpha_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n = 2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mean_ratio = pytree_mean(var_exact) / pytree_mean(var_resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.12911958054127\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(mean_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': {'bias': Array([0.94798186, 0.93445518, 1.05770642, 0.9177523 , 1.03299275,\n",
       "         1.03832406, 0.96197603, 1.07071494, 1.03794047, 0.97685504,\n",
       "         0.96668562, 1.05117939, 0.92989883, 0.97273154, 1.03660041,\n",
       "         1.03166638, 0.96192518, 0.9931266 , 0.96217681, 0.8604974 ,\n",
       "         0.98463323, 0.99289561, 0.96640825, 0.99972348, 0.94932979,\n",
       "         1.07249183, 0.95514303, 0.8939865 , 0.9855491 , 1.01235135,\n",
       "         0.99162151, 1.1014438 , 0.91654865, 0.99931935, 0.88922758,\n",
       "         1.0032648 , 0.97594523, 1.02288995, 1.0329321 , 0.96949903,\n",
       "         0.97110824, 1.03157805, 1.01907588, 1.00319094, 0.99868767,\n",
       "         1.02461605, 0.99448677, 0.99283738], dtype=float64),\n",
       "  'kernel': Array([[0.97906245, 0.99513282, 1.02232741, 1.02042556, 0.95849349,\n",
       "          1.01011261, 1.06894005, 0.96622769, 0.95855709, 1.02836845,\n",
       "          0.96094697, 1.00877245, 1.0309354 , 1.00383187, 0.96546077,\n",
       "          1.03172647],\n",
       "         [0.94768516, 0.93217715, 0.96832394, 0.9687081 , 0.98626495,\n",
       "          0.97252199, 0.95787331, 0.94515029, 0.97440726, 1.03096332,\n",
       "          0.89724499, 0.93368346, 1.01311448, 0.9677221 , 0.96155572,\n",
       "          0.94711682],\n",
       "         [1.08435799, 1.03514029, 1.03483497, 1.03153561, 1.01904489,\n",
       "          1.03674034, 1.04065292, 1.05915756, 1.0342895 , 1.09185343,\n",
       "          1.01416171, 1.03914569, 1.05685851, 1.05255809, 0.99896476,\n",
       "          1.01639699],\n",
       "         [1.02787764, 0.91160846, 0.96600025, 0.95145364, 0.95504426,\n",
       "          1.01233003, 0.97910314, 0.93914683, 0.95156175, 0.96396812,\n",
       "          0.92915863, 0.96595427, 0.96868248, 0.98662161, 0.93989538,\n",
       "          0.99939594],\n",
       "         [1.05552356, 1.03745553, 1.00974322, 1.02089541, 0.98477479,\n",
       "          0.97696226, 0.97239843, 1.00687207, 0.97803817, 1.01781322,\n",
       "          0.96876488, 0.96034636, 1.03495469, 1.0009433 , 1.04532323,\n",
       "          1.02061366],\n",
       "         [0.99565221, 0.99490245, 1.05335017, 1.02206137, 1.03557964,\n",
       "          1.06464864, 1.02144389, 1.00204356, 0.97360221, 1.0055659 ,\n",
       "          1.05994968, 1.06111321, 1.00762843, 1.00531398, 1.03975591,\n",
       "          1.0071308 ],\n",
       "         [0.94794994, 0.93187445, 0.98154016, 0.94760619, 0.99143457,\n",
       "          0.98105355, 0.92901457, 0.97937973, 1.02708779, 1.0119359 ,\n",
       "          1.05092569, 0.93676316, 0.9250127 , 0.96696237, 0.96968751,\n",
       "          0.98816984],\n",
       "         [1.07037092, 1.05819931, 1.08806425, 1.07448068, 1.10137126,\n",
       "          1.06221961, 1.06345181, 1.08441882, 1.03048351, 1.0332985 ,\n",
       "          1.05693136, 1.04520566, 1.04493711, 1.10025604, 1.08312572,\n",
       "          1.07700147],\n",
       "         [1.06197866, 1.04579236, 1.05663836, 1.04447133, 1.0070605 ,\n",
       "          1.08540619, 1.05355466, 1.10078606, 1.05930639, 1.02389438,\n",
       "          1.09083121, 1.06503902, 1.04314166, 1.0998786 , 1.08617421,\n",
       "          1.02618629],\n",
       "         [1.0200011 , 0.95163519, 0.93966883, 0.90005325, 0.92851542,\n",
       "          0.9840004 , 0.95941971, 0.92755025, 0.9630455 , 1.00494902,\n",
       "          0.95079086, 0.94478125, 0.92625201, 0.9641875 , 0.99783147,\n",
       "          0.95714884],\n",
       "         [0.98550595, 0.97379328, 0.91116262, 0.99327205, 0.9349417 ,\n",
       "          0.96429937, 0.95944325, 0.96667682, 0.93180379, 1.03830154,\n",
       "          0.96375985, 0.93951721, 0.94698611, 0.97040453, 0.9890366 ,\n",
       "          0.92318966],\n",
       "         [1.07575675, 1.03285231, 1.07956226, 1.03443284, 1.00283694,\n",
       "          1.06896621, 1.03021306, 1.04823559, 1.02887317, 1.02332649,\n",
       "          1.07688385, 1.09705115, 1.00002335, 1.03463963, 1.02881671,\n",
       "          0.99668769],\n",
       "         [1.01725464, 1.06741558, 0.96800255, 0.94765025, 0.95119596,\n",
       "          1.00271006, 0.93607092, 0.94909005, 0.97990581, 0.99918202,\n",
       "          0.93878283, 0.94273062, 0.95726577, 0.9807109 , 0.96925726,\n",
       "          0.96511399],\n",
       "         [1.04112795, 1.03096369, 1.04414282, 0.99733102, 1.0385356 ,\n",
       "          1.00194573, 1.01666201, 0.97633242, 1.03358721, 1.0120753 ,\n",
       "          1.04582911, 1.05380465, 1.03269642, 1.01519511, 1.01293816,\n",
       "          1.02683948],\n",
       "         [1.07641873, 1.05524212, 1.00500171, 0.99692917, 0.99512137,\n",
       "          1.09089588, 1.04906049, 1.10863475, 1.02801943, 1.06140145,\n",
       "          0.99637294, 0.99291284, 1.05018204, 1.05142061, 1.04002291,\n",
       "          0.98683733],\n",
       "         [1.08718277, 0.98849344, 1.02159525, 1.07230888, 1.03255052,\n",
       "          1.01735784, 1.01881548, 1.08666671, 1.01707686, 1.05484951,\n",
       "          1.05011056, 1.0821695 , 1.0413357 , 1.03921323, 1.04112891,\n",
       "          0.99934303],\n",
       "         [0.99722397, 0.94004351, 0.99286948, 0.97483316, 0.91035765,\n",
       "          0.97913861, 0.9392069 , 0.95957906, 1.03590562, 0.96001537,\n",
       "          1.04117922, 0.96468742, 0.99752423, 1.00091744, 0.95096156,\n",
       "          0.93911037],\n",
       "         [1.01783643, 0.96161756, 0.97381566, 1.01685663, 1.03514507,\n",
       "          1.02992775, 0.97972738, 1.01801792, 0.97813061, 1.03458995,\n",
       "          1.05500597, 0.98607076, 0.97057613, 1.00430728, 1.02251089,\n",
       "          0.96976107],\n",
       "         [0.97065661, 0.92449002, 0.97575854, 0.9899921 , 0.94984112,\n",
       "          1.05446121, 0.9816713 , 0.97524319, 0.94319492, 0.99438444,\n",
       "          0.99461393, 1.01022761, 1.02586804, 1.00016573, 0.99158857,\n",
       "          0.98938592],\n",
       "         [1.02828423, 0.93620011, 0.93568618, 0.92197693, 0.90670508,\n",
       "          0.92109834, 0.91227879, 0.90133083, 0.91145946, 0.94083466,\n",
       "          0.95402517, 0.93438404, 0.92200955, 0.93200854, 0.92399949,\n",
       "          0.93729404],\n",
       "         [0.99017802, 0.96471253, 1.03854054, 0.97608803, 0.99956519,\n",
       "          1.00807569, 1.06092873, 0.98488463, 1.02400866, 0.96596571,\n",
       "          1.09298403, 1.01356058, 1.0212722 , 1.04407244, 1.02256726,\n",
       "          1.0129269 ],\n",
       "         [1.00825898, 0.95096605, 0.95954119, 0.9512512 , 0.98062923,\n",
       "          1.01176969, 1.00329819, 0.94880573, 0.92613916, 1.00413616,\n",
       "          0.95702397, 0.92823776, 0.99034859, 1.00772658, 1.06493217,\n",
       "          1.02213792],\n",
       "         [1.02469364, 0.96909966, 1.03591118, 1.01031132, 1.01699659,\n",
       "          1.01754639, 0.99784516, 0.98600592, 0.99249158, 0.97917122,\n",
       "          1.01578605, 1.02137976, 1.03583099, 0.99305037, 1.00735792,\n",
       "          1.03590509],\n",
       "         [0.97796145, 0.93403996, 1.01028156, 0.97183089, 0.9996462 ,\n",
       "          1.00113759, 0.99357289, 0.96569184, 0.98736096, 1.00235878,\n",
       "          0.95788074, 0.94383038, 0.92604628, 1.03059525, 0.92723447,\n",
       "          0.96946731],\n",
       "         [0.98409803, 0.90653967, 0.94167161, 0.95685151, 0.89745488,\n",
       "          0.86966193, 1.01267737, 0.93733663, 0.96821721, 0.95346797,\n",
       "          0.92981371, 0.9570959 , 0.94585303, 1.00771452, 1.01054339,\n",
       "          0.97192785],\n",
       "         [0.97677808, 1.00841275, 0.99324573, 1.01450254, 0.97255311,\n",
       "          0.95382283, 0.98140034, 1.00785629, 0.92154382, 1.03321251,\n",
       "          0.97883725, 0.96513983, 1.00365298, 1.03240939, 1.05741499,\n",
       "          0.99548001],\n",
       "         [0.97776793, 1.00274932, 0.98490893, 0.9985941 , 0.98366104,\n",
       "          1.00376946, 0.98236637, 0.97551736, 0.92153412, 1.00931269,\n",
       "          0.976683  , 0.98706474, 0.93629678, 0.98814636, 0.99651722,\n",
       "          0.98509801],\n",
       "         [1.00756416, 0.92238335, 0.95557551, 0.94987401, 0.90484755,\n",
       "          1.00553186, 0.93540603, 0.957586  , 0.92800417, 0.98755603,\n",
       "          0.96321797, 0.90402567, 0.92481477, 0.96632235, 0.97731461,\n",
       "          0.9839683 ],\n",
       "         [0.98315536, 0.95145488, 0.97249147, 0.93176193, 0.93417546,\n",
       "          0.95059103, 1.02964102, 0.98058825, 1.02534248, 0.99196106,\n",
       "          1.01928062, 0.91015158, 0.94627366, 0.95520726, 1.01567182,\n",
       "          1.0225756 ],\n",
       "         [1.04819056, 1.03545487, 1.01661068, 0.98844046, 1.05431811,\n",
       "          1.04347111, 1.03117771, 1.08877339, 1.05585639, 1.05533303,\n",
       "          1.10223909, 1.00896699, 1.07758567, 1.09918487, 1.01899915,\n",
       "          1.07731917],\n",
       "         [0.9966048 , 1.01529077, 0.97987324, 0.99004644, 0.98845849,\n",
       "          1.00365034, 1.00324327, 1.0422458 , 1.02371673, 1.02273124,\n",
       "          1.03647183, 0.99741658, 1.00031637, 1.00603726, 1.02081857,\n",
       "          1.00671149],\n",
       "         [1.04930498, 0.97768773, 1.06750164, 1.08444417, 1.04615177,\n",
       "          1.04293755, 1.06101407, 1.08008791, 1.04381208, 1.07750668,\n",
       "          1.04726431, 1.04732569, 1.10092854, 1.05039771, 1.06792918,\n",
       "          1.03195534],\n",
       "         [1.01903401, 0.95978758, 0.97946524, 0.97004522, 0.93246154,\n",
       "          0.95407227, 1.00312584, 0.96088632, 0.9096687 , 0.9713635 ,\n",
       "          0.96263172, 0.96983905, 0.99512075, 0.97831529, 0.96607931,\n",
       "          0.95018697],\n",
       "         [1.06649122, 1.02816152, 1.04622893, 1.08685293, 1.00345646,\n",
       "          1.02312116, 1.04988774, 1.09668739, 0.97164235, 1.05293   ,\n",
       "          1.03995348, 0.99222294, 1.06861826, 1.04359968, 1.02733202,\n",
       "          1.02067812],\n",
       "         [0.93132678, 0.86923392, 0.90274545, 0.90609557, 0.90721943,\n",
       "          0.89773089, 0.94359495, 0.92729485, 0.93305664, 0.89220424,\n",
       "          0.91258188, 0.931943  , 0.9576591 , 0.94166587, 0.94993969,\n",
       "          0.96906442],\n",
       "         [1.04983255, 0.97096706, 0.98500827, 1.05648432, 0.9757338 ,\n",
       "          1.03325536, 1.08195339, 1.01568931, 0.91590611, 1.03674766,\n",
       "          1.00590591, 0.9665376 , 1.00653382, 1.00004408, 1.04963106,\n",
       "          1.07588977],\n",
       "         [1.06169626, 1.07368285, 1.00659567, 1.06210579, 0.96012734,\n",
       "          1.02853957, 1.02755293, 0.99197506, 0.95153392, 1.11427883,\n",
       "          1.00540283, 0.96845072, 0.9539023 , 0.97399236, 1.01331574,\n",
       "          0.98205176],\n",
       "         [1.11259438, 1.06168711, 1.01708939, 1.01967035, 1.04366945,\n",
       "          1.03037245, 1.0794372 , 1.01078163, 1.07300882, 1.00535942,\n",
       "          1.07889923, 1.03854201, 1.00222739, 1.07472453, 1.01458659,\n",
       "          1.0454516 ],\n",
       "         [1.05817003, 0.98987087, 1.02614434, 1.04208973, 1.03984719,\n",
       "          1.06976102, 0.95335453, 1.02623088, 0.96710232, 1.02359171,\n",
       "          1.03029843, 1.0547166 , 1.06461031, 1.06147071, 1.00611496,\n",
       "          1.00890194],\n",
       "         [0.9618097 , 0.98235351, 0.9623509 , 0.99943353, 0.96576592,\n",
       "          0.99527088, 0.97924855, 1.01472988, 0.94937132, 0.99168329,\n",
       "          0.99674313, 1.00448068, 1.03180887, 0.99439975, 1.07715341,\n",
       "          0.90698822],\n",
       "         [1.04428047, 0.98760722, 0.98167012, 0.96796247, 0.98784401,\n",
       "          0.98451916, 1.00578628, 1.01577659, 0.96961097, 0.99962249,\n",
       "          1.00924922, 1.01151015, 1.00806215, 0.97575782, 0.99954266,\n",
       "          0.96043253],\n",
       "         [1.02498496, 0.96422635, 1.01459901, 1.00988948, 0.97914251,\n",
       "          1.03763674, 1.00586474, 1.0254211 , 1.03721994, 1.02133571,\n",
       "          1.06686338, 1.01908138, 0.99589993, 0.99667747, 1.03832139,\n",
       "          0.995716  ],\n",
       "         [1.04639408, 1.0219449 , 1.06837428, 0.98591082, 0.98763501,\n",
       "          1.05487724, 1.03090071, 1.02958196, 0.98687407, 1.01988893,\n",
       "          1.04112669, 1.03107039, 0.97950656, 1.01018234, 1.10287054,\n",
       "          1.06365499],\n",
       "         [1.01660538, 0.96449466, 0.99105109, 0.96764914, 1.04066446,\n",
       "          1.051962  , 0.99624882, 0.9927702 , 0.99397267, 1.0245065 ,\n",
       "          1.01054935, 1.01662245, 0.99304164, 1.00516123, 1.00799648,\n",
       "          1.06379901],\n",
       "         [0.97565679, 0.94551419, 0.97494946, 0.94036359, 0.94089766,\n",
       "          0.94505111, 0.98837368, 1.0058837 , 0.95297631, 0.99859029,\n",
       "          1.0232827 , 0.98173726, 1.02547743, 0.97203753, 1.02369756,\n",
       "          1.02857992],\n",
       "         [1.06084896, 0.95801841, 0.99592483, 0.97325138, 0.93365654,\n",
       "          1.02721349, 0.97903617, 1.01326023, 1.01235142, 1.04802449,\n",
       "          1.07276845, 0.98945772, 0.96471509, 1.01456837, 1.03908441,\n",
       "          0.99379028],\n",
       "         [1.05067596, 1.01804052, 0.99858083, 0.99009538, 0.96050018,\n",
       "          0.98836639, 1.01753927, 1.04919813, 0.99558034, 1.08158838,\n",
       "          1.07118046, 0.97792238, 1.01442591, 1.00769761, 1.034259  ,\n",
       "          0.99622769],\n",
       "         [0.97805575, 0.95443295, 1.03309322, 1.00664786, 0.9738207 ,\n",
       "          1.03387985, 1.04313279, 1.00182441, 1.01527228, 0.99902373,\n",
       "          1.02977497, 1.02926983, 1.05261591, 0.99703486, 1.08199338,\n",
       "          1.02929612]], dtype=float64)},\n",
       " 'visible_bias': Array([1.04056319, 1.01480796, 0.98161694, 0.95684565, 0.99148113,\n",
       "        0.96102148, 0.99501946, 0.98241215, 0.98050902, 1.04125525,\n",
       "        0.99425534, 0.96409755, 1.03068874, 1.01556149, 0.98603465,\n",
       "        1.01066718], dtype=float64)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tree_map(lambda x,y: x/y.T/240, var_exact, var_resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "is_op = IS_Operator(operator = trainer.model.H_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.9910-0.0023j ± 0.0023 [σ²=0.0550]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# no is, calculations done with vstate\n",
    "trainer.vstate.expect(trainer.model.H_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/.amisery/netket/lib/python3.11/site-packages/netket/utils/struct/pytree.py:55: UserWarning: Constructing the SR object with `SR(qgt= MyQGTType({'diag_scale', 'diag_shift'}))` can lead to unexpected results and has been deprecated, because the keyword arguments specified in the QGTType are overwritten by those specified by the SR class and its defaults.\n",
      "\n",
      "To fix this, construct SR as  `SR(qgt=MyQGTType, {'diag_scale': None, 'diag_shift': 0.0})` .\n",
      "\n",
      "In the future, this warning will become an error.\n",
      "  obj.__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED: [-25.05419813]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qgt1 =QGTJacobianDenseImportanceSampling(\n",
    "    importance_operator=is_op, chunk_size=trainer.chunk_size_jac\n",
    ")\n",
    "sr_is = nk.optimizer.SR(qgt=qgt1, diag_shift=1e-4, solver=nk.optimizer.solver.cholesky, holomorphic=True)\n",
    "\n",
    "print(\"ED:\", nk.exact.lanczos_ed(is_op.operator))\n",
    "\n",
    "log = nk.logging.RuntimeLog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f90fa106db429bb867c30bb40e182c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sr \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mSR(solver\u001b[38;5;241m=\u001b[39mnk\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mcholesky, diag_shift\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, holomorphic\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m gs_is \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mVMC(is_op, opt, variational_state\u001b[38;5;241m=\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvstate, preconditioner\u001b[38;5;241m=\u001b[39msr_is)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mgs_is\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# trainer.gs.run(n_iter=100)\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/netket/driver/abstract_variational_driver.py:354\u001b[0m, in \u001b[0;36mAbstractVariationalDriver.run\u001b[0;34m(self, n_iter, out, obs, step_size, show_progress, save_params_every, write_every, callback, timeit)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# if the cost-function is defined then report it in the progress bar\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\n\u001b[0;32m--> 354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_stats)\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m     log_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_stats\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Execute callbacks before loggers because they can append to log_data\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/netket/stats/mc_stats.py:113\u001b[0m, in \u001b[0;36mStats.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# extract adressable data from fully replicated arrays\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m extract_replicated(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m     mean, err, var \u001b[38;5;241m=\u001b[39m \u001b[43m_format_decimal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_of_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m math\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR_hat):\n\u001b[1;32m    115\u001b[0m         ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, R̂=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR_hat\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/netket/stats/mc_stats.py:31\u001b[0m, in \u001b[0;36m_format_decimal\u001b[0;34m(value, std, var)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_decimal\u001b[39m(value, std, var):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39misfinite(std) \u001b[38;5;129;01mand\u001b[39;00m std \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-7\u001b[39m:\n\u001b[1;32m     32\u001b[0m         decimals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog10(std))), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0:.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124mf}\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(value, decimals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0:.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124mf}\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(std, decimals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0:.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124mf}\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var, decimals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     37\u001b[0m         )\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/jax/_src/array.py:294\u001b[0m, in \u001b[0;36mArrayImpl.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    293\u001b[0m   core\u001b[38;5;241m.\u001b[39mcheck_bool_conversion(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 294\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m)\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/scratch/.amisery/netket/lib/python3.11/site-packages/jax/_src/array.py:628\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "opt = nk.optimizer.Sgd(learning_rate=0.005)\n",
    "op = trainer.model.H\n",
    "sr = nk.optimizer.SR(solver=nk.optimizer.solver.cholesky, diag_shift=1e-4, holomorphic= True)\n",
    "gs_is = nk.VMC(is_op, opt, variational_state=trainer.vstate, preconditioner=sr_is)\n",
    "gs_is.run(n_iter=2000)\n",
    "# trainer.gs.run(n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling IS expect function\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-12.0098+0.0010j ± 0.0024 [σ²=0.0880]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gs_is.state.expect(is_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exp, force_psi = trainer.vstate.expect_and_forces(trainer.model.H_jax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exp, force_hpsi =  gs_is.state.expect_and_forces(is_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vstate_fs = nk.vqs.FullSumState(hilbert=trainer.model.hi, model=trainer.ansatz, chunk_size=trainer.chunk_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fs_e, force_fs = vstate_fs.expect_and_forces(trainer.model.H_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.999e+00-1.735e-18j ± 0.000e+00 [σ²=1.799e+01]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fs_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': {'bias': Array([0.93092402, 0.19469222, 0.60256542, 0.8036909 , 0.34496903,\n",
       "         0.43552084, 0.17513618, 0.64318799, 3.97186977], dtype=float64),\n",
       "  'kernel': Array([[ 14.94007571,   6.90408318,  15.42507549,   2.96411414,\n",
       "           14.23575427,   4.3459032 ,  25.14661862,   7.8418824 ,\n",
       "            7.68163779],\n",
       "         [ 13.89436609,  18.29542463,  10.73803377,  17.07277434,\n",
       "           23.18548465,  11.3972946 ,   9.46632964,  17.70094328,\n",
       "            7.63903291],\n",
       "         [  4.87370661,   4.4401314 ,  18.63329821,  60.03650311,\n",
       "            5.54178775,   8.5246653 ,   8.05146881,   4.54279373,\n",
       "           41.89261462],\n",
       "         [ 12.79485815,  19.60852314,   2.85288104,  17.0839438 ,\n",
       "            3.54469869,   5.41633179,   4.54571301,  23.10802942,\n",
       "            1.34889913],\n",
       "         [ 19.29749448,  10.68603671,  25.43181035,   7.30196509,\n",
       "            7.06289746,  13.45059398,  13.43261433,  24.2749312 ,\n",
       "           10.8381639 ],\n",
       "         [  7.87447127,  11.598522  ,   6.86868562,  10.81785669,\n",
       "            6.63457017,   6.17584726,   7.6981173 ,   8.5944358 ,\n",
       "           26.6942294 ],\n",
       "         [  8.45564279,  13.37067694,   1.56199856,   3.74442506,\n",
       "            9.31865206,  27.61119009,  10.26571595,  56.52446196,\n",
       "           22.63353256],\n",
       "         [543.25738018,  13.56427155,  20.3931229 ,  19.12880222,\n",
       "           31.11740375,   5.63219384,  11.79250211,  12.37112097,\n",
       "           38.81609513],\n",
       "         [ 16.91224592,   7.77527051,  55.99886749,  19.99344734,\n",
       "            3.81386874,  16.07387307,   3.6263789 ,  14.81914316,\n",
       "           47.82907349]], dtype=float64)},\n",
       " 'visible_bias': Array([ 0.76210499,  9.14479393, 16.28505187,  5.12001805,  2.97122484,\n",
       "        20.25250195,  4.19657663,  3.50300776,  5.78959885], dtype=float64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "jax.tree_util.tree_map(lambda x,y: jnp.abs(x/y), force_fs, force_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense': {'bias': Array([0.88612486, 0.13404208, 0.99371087, 0.84443808, 0.31374175,\n",
       "         0.5260428 , 0.646892  , 0.59339698, 0.70365368], dtype=float64),\n",
       "  'kernel': Array([[24.2962961 ,  8.64068893, 15.49768011, 17.08338936, 10.67443608,\n",
       "           6.19249675,  4.83248955, 13.60913754,  2.91133851],\n",
       "         [23.74601295, 15.53804373, 17.24533432, 16.19886708,  8.9841118 ,\n",
       "           2.50129764,  9.14147717, 27.39917294, 31.73628948],\n",
       "         [ 8.83096568, 17.87887555, 12.14997468, 22.53397512,  6.36807376,\n",
       "          13.37405873,  3.47667187, 35.34127013, 43.8496282 ],\n",
       "         [ 8.17360671, 12.03829636,  3.6821588 , 14.69951997,  3.80583798,\n",
       "           8.56187697,  7.27511624, 11.03965761,  1.28822285],\n",
       "         [20.3140993 ,  8.07311876, 21.15403205,  5.9070311 , 29.27741423,\n",
       "           8.14823679, 16.81618266,  8.12369981, 19.69084503],\n",
       "         [14.38473771, 12.96873877,  7.66741867,  8.99278708,  7.43838629,\n",
       "          11.30984246, 27.4971089 ,  8.31011023,  8.82746784],\n",
       "         [ 8.92956817, 25.02186124,  2.15459126,  5.23131137, 12.97369661,\n",
       "          19.4465037 , 11.30514994,  8.47248684, 17.31008579],\n",
       "         [11.1425807 , 11.98693737, 18.08804644,  4.13910497, 45.90862368,\n",
       "           7.86551047, 58.974058  , 46.46204259, 17.01872029],\n",
       "         [15.38790747, 32.81850338, 18.48370788, 29.76227818,  1.85051328,\n",
       "           4.16736243,  3.30140728, 11.16948921, 32.03285348]],      dtype=float64)},\n",
       " 'visible_bias': Array([ 4.64274761,  8.47092191, 24.65390589, 34.75638032, 15.09948482,\n",
       "        17.63376058,  6.75214277, 27.90829683,  4.71733102], dtype=float64)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "jax.tree_util.tree_map(lambda x,y: jnp.abs(x/y), force_fs, force_hpsi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netket",
   "language": "python",
   "name": "netket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
